{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install music21 numpy tensorflow scikit-learn tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from music21 import *\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input, Dropout\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_files(file):\n",
        "    notes = []\n",
        "    notes_to_parse = None\n",
        "\n",
        "    midi = converter.parse(file)\n",
        "    instrmt = instrument.partitionByInstrument(midi)\n",
        "\n",
        "    for part in instrmt.parts:\n",
        "        if 'Piano' in str(part):\n",
        "            notes_to_parse = part.recurse()\n",
        "            for element in notes_to_parse:\n",
        "                if isinstance(element, note.Note):\n",
        "                    notes.append(str(element.pitch))\n",
        "                elif isinstance(element, chord.Chord):\n",
        "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "    return notes\n",
        "\n",
        "file_path = [\"balakir\"]\n",
        "all_files = glob.glob('data/All Midi Files/' + file_path[0] + '/*.mid', recursive=True)\n",
        "notes_array = np.array([read_files(i) for i in tqdm(all_files)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "notess = sum(notes_array, [])\n",
        "unique_notes = list(set(notess))\n",
        "print(\"Unique Notes:\", len(unique_notes))\n",
        "\n",
        "freq = dict(map(lambda x: (x, notess.count(x)), unique_notes))\n",
        "\n",
        "for i in range(30, 100, 20):\n",
        "    print(i, \":\", len(list(filter(lambda x: x[1] >= i, freq.items()))))\n",
        "\n",
        "freq_notes = dict(filter(lambda x: x[1] >= 50, freq.items()))\n",
        "new_notes = [[i for i in j if i in freq_notes] for j in notes_array]\n",
        "ind2note = dict(enumerate(freq_notes))\n",
        "note2ind = dict(map(reversed, ind2note.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timesteps = 50\n",
        "x = []\n",
        "y = []\n",
        "for i in new_notes:\n",
        "    for j in range(0, len(i) - timesteps):\n",
        "        inp = i[j:j + timesteps]\n",
        "        out = i[j + timesteps]\n",
        "        x.append(list(map(lambda x: note2ind[x], inp)))\n",
        "        y.append(note2ind[out])\n",
        "x_new = np.array(x)\n",
        "y_new = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_new = np.reshape(x_new, (len(x_new), timesteps, 1))\n",
        "y_new = np.reshape(y_new, (-1, 1))\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_new, y_new, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, return_sequences=True, input_shape=(x_new.shape[1], x_new.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(len(note2ind), activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(\"model/best_model.h5\", save_best_only=True)\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=128,\n",
        "    epochs=80,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "last_epoch_accuracy = history.history['accuracy'][-1]\n",
        "print(\"Accuracy of the last epoch: {:.2f}%\".format(last_epoch_accuracy * 100))\n",
        "model.save(\"model/s2s2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_model(\"model/s2s2\")\n",
        "index = np.random.randint(0, len(x_test)-1)\n",
        "music_pattern = x_test[index]\n",
        "out_pred = []\n",
        "for i in range(200):\n",
        "    music_pattern = music_pattern.reshape(1, len(music_pattern), 1)\n",
        "    pred_index = np.argmax(model.predict(music_pattern, verbose=0))\n",
        "    out_pred.append(ind2note[pred_index])\n",
        "    music_pattern = np.append(music_pattern, pred_index)\n",
        "    music_pattern = music_pattern[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_notes = []\n",
        "for offset, pattern in enumerate(out_pred):\n",
        "    if ('.' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            i_curr_note = int(current_note)\n",
        "            new_note = note.Note(i_curr_note)\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "os.makedirs(\"output\", exist_ok=True)\n",
        "midi_stream.write('midi', fp='output/pred_music.mid')\n",
        "print(\"\ud83c\udfb6 Music generated and saved as output/pred_music.mid\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}